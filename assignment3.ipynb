{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3Jp_VhCl4te",
    "tags": []
   },
   "source": [
    "# MΥΕ046 – Υπολογιστική Όραση: Άνοιξη 2023\n",
    "## 3η Σειρά Ασκήσεων: 50% του συνολικού βαθμού\n",
    "## Διδάσκων: Άγγελος Γιώτης\n",
    "- ΠΑΡΑΔΟΣΗ: **Σάββατο, 10 Ιουνίου, 2023 23:59**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOXXS2dOl4tj",
    "tags": []
   },
   "source": [
    "# Γενικές Οδηγίες\n",
    "\n",
    "Απαντήστε στα παρακάτω ζητήματα χρησιμοποιώντας Python στο συνημμένο σημειωματάριο Jupyter και ακολουθήστε τις παρακάτω οδηγίες:\n",
    " \n",
    "- Οι ασκήσεις είναι **ατομικές** - δεν επιτρέπεται η μεταξύ σας συνεργασία για την υλοποίηση/παράδοσή τους.\n",
    "\n",
    "- **Δεν** επιτρέπεται να χρησιμοποιήσετε κώδικα που τυχόν θα βρείτε στο διαδίκτυο (είτε αυτούσιο, είτε **παραγόμενο από ΑΙ**). Η χρήση κώδικα τρίτων θα έχει σαν αποτέλεσμα τον αυτόματο μηδενισμό σας.\n",
    "\n",
    "- Όλες οι λύσεις πρέπει να είναι γραμμένες σε αυτό το σημειωματάριο `Jupyter notebook`.\n",
    "\n",
    "* **Εάν** ένα ζήτημα περιλαμβάνει θεωρητική ερώτηση, η απάντηση θα **πρέπει** να συμπεριληφθεί στο τέλος του ζητήματος, σε ξεχωριστό \"Markdown\" κελί.\n",
    "\n",
    "- Ο κώδικάς σας πρέπει να σχολιαστεί εκτενώς!\n",
    "\n",
    "- Αφού ολοκληρώσετε (υλοποιήσετε και εκτελέσετε) τις απαντήσεις σας στο σημειωματάριο (notebook), εξαγάγετε το notebook ως PDF και υποβάλετε, τόσο το σημειωματάριο όσο και το PDF (δηλαδή τα αρχεία `.ipynb` και `.pdf`) στο `turnin` του μαθήματος, μαζί με ένα συνοδευτικό αρχείο `onoma.txt` που θα περιέχει το ον/μο σας και τον Α.Μ. σας.\n",
    "\n",
    "- Οι απαντήσεις θα παραδοθούν με την εντολή: **turnin assignment_3@mye046 onoma.txt assignment3.ipynb assignment3.pdf**\n",
    "\n",
    "- Μπορείτε να χρησιμοποιήσετε βασικά πακέτα γραμμικής άλγεβρας (π.χ. `NumPy`, `SciPy`), αλλά δεν επιτρέπεται να χρησιμοποιείτε τα πακέτα/βιβλιοθήκες που επιλύουν άμεσα τα προβλήματα, εκτός και αν αναφέρεται διαφορετικά η χρήση συγκεκριμένου πακέτου σε κάποιο ζήτημα. Αν δεν είστε βέβαιοι για κάποιο συγκεκριμένο πακέτο/βιβλιοθήκη ή συνάρτηση που θα χρησιμοποιήσετε, μη διστάσετε να ρωτήσετε τον διδάσκοντα.\n",
    "\n",
    "- Συνιστάται ιδιαίτερα να αρχίσετε να εργάζεστε στις ασκήσεις σας το συντομότερο δυνατό!\n",
    "\n",
    "**Late Policy:** Εργασίες που υποβάλλονται καθυστερημένα θα λαμβάνουν μείωση βαθμού 10% για κάθε 24 ώρες καθυστέρησης. Οι εργασίες δεν θα γίνονται δεκτές 96 ώρες (4 ημέρες) μετά την προθεσμία παράδοσης. Για παράδειγμα, παράδοση της εργασίας 2 ημέρες μετά την προθεσμία βαθμολογείται με άριστα το 40 (από 50)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5pbyh5yl4tk",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Άσκηση 1: Μηχανική Μάθηση [25 μονάδες]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m16Ecnjdl4tk"
   },
   "source": [
    "Στην άσκηση αυτή θα υλοποιήσετε μια σειρά από τεχνικές μηχανικής μάθησης με εφαρμογή στην επίλυση προβλημάτων υπολογιστικής όρασης."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQpyhnvIl4tk"
   },
   "source": [
    "### Ζήτημα 1.1: Αρχική Εγκατάσταση"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCC0JD1Il4tl"
   },
   "source": [
    "Θα χρησιμοποιήσουμε την ενότητα [Scikit-learn (Sklearn)](https://scikit-learn.org/stable/) για αυτή την άσκηση. Είναι μια από τις πιο χρήσιμες και ισχυρές βιβλιοθήκες για μηχανική μάθηση στην Python. Παρέχει μια επιλογή αποτελεσματικών εργαλείων για μηχανική μάθηση και στατιστική μοντελοποίηση, συμπεριλαμβανομένης της ταξινόμησης (classification), της παλινδρόμησης (regression), της ομαδοποίησης (clustering) και της μείωσης διάστασης (dimensionality reduction). Αυτό το πακέτο, το οποίο είναι σε μεγάλο βαθμό γραμμένο σε Python, βασίζεται στις βιβλιοθήκες NumPy, SciPy και Matplotlib.\n",
    "\n",
    "Αρχικά καλούμε/εγκαθιστούμε τη βασική μονάδα της βιβλιοθήκης sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZiYlaSol4tm"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SQL5iPKl4to"
   },
   "source": [
    "### Ζήτημα 1.2: Λήψη συνόλου δεδομένων χειρόγραφων ψηφίων \"MNIST\" και απεικόνιση παραδειγμάτων [2 μονάδες]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_f1_Tz7l4tq"
   },
   "source": [
    "Η βάση δεδομένων [MNIST](https://en.wikipedia.org/wiki/MNIST_database) (Modified National Institute of Standards and Technology database) είναι ένα αρκετά διαδεδομένο σύνολο δεδομένων που αποτελείται από εικόνες χειρόγραφων ψηφίων, διαστάσεων 28x28 σε κλίμακα του γκρι. Για αυτό το ζήτημα, θα χρησιμοποιήσουμε το πακέτο Sklearn για να κάνουμε ταξινόμηση μηχανικής μάθησης στο σύνολο δεδομένων MNIST.\n",
    "\n",
    "Το Sklearn παρέχει μια βάση δεδομένων MNIST χαμηλότερης ανάλυσης με εικόνες ψηφίων 8x8 pixel. Το πεδίο (attribute) `images` του συνόλου δεδομένων, αποθηκεύει πίνακες 8x8 τιμών κλίμακας του γκρι για κάθε εικόνα. Το πεδίο (attribute) `target` του συνόλου δεδομένων αποθηκεύει το ψηφίο που αντιπροσωπεύει κάθε εικόνα. Ολοκληρώστε τη συνάρτηση 'plot_mnist_sample()' για να απεικονίσετε σε ένα σχήμα 2x5 ένα δείγμα εικόνας από κάθε μια κατηγορία (κάθε πλαίσιο του 2x5 σχήματος αντιστοιχεί σε ένα ψηφίο/εικόνα μιας κατηγορίας). Η παρακάτω εικόνα δίνει ένα παράδειγμα:\n",
    "<!-- <img src=\"./images/examples_mnist.PNG\" alt=\"drawing\" width=\"400\"/> -->\n",
    "![mnist](images/examples_mnist.PNG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbXpRqO1l4tq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PTXSZhWl4tr"
   },
   "outputs": [],
   "source": [
    "# Download MNIST Dataset from Sklearn\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Print to show there are 1797 images (8 by 8)\n",
    "print(\"Images Shape\" , digits.images.shape)\n",
    "\n",
    "# Print to show there are 1797 image data (8 by 8 images for a dimensionality of 64)\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "\n",
    "# Print to show there are 1797 labels (integers from 0-9)\n",
    "print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p43geFB4l4tr"
   },
   "outputs": [],
   "source": [
    "def plot_mnist_sample(digits):\n",
    "    \"\"\"\n",
    "    This function plots a sample image for each category,\n",
    "    The result is a figure with 2x5 grid of images.\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEj8kOdul4tr"
   },
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT CHANGE\n",
    "# This code is for you to plot the results.\n",
    "\n",
    "plot_mnist_sample(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD68VE3pl4ts"
   },
   "source": [
    "### Ζήτημα 1.3: Αναγνώριση χειρόγραφων ψηφίων με Sklearn [4 μονάδες]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ctL_Gwl4ts"
   },
   "source": [
    "Ένα από τα πιο ενδιαφέροντα πράγματα σχετικά με τη βιβλιοθήκη Sklearn είναι ότι παρέχει έναν εύκολο τρόπο δημιουργίας και κλήσης/χρήσης διαφορετικών μοντέλων. Σε αυτό το μέρος της άσκησης, θα αποκτήσετε εμπειρία με τα μοντέλα ταξινόμησης `LogisticRegressionClassifier` (ταξινόμηση με λογιστική παλινδρόμηση) και `kNNCalssifier` (ταξινόμηση με τη μέθοδο κ-κοντινότερων γειτόνων).\n",
    "\n",
    "Ακολουθούν αρχικά 2 βοηθητικές ρουτίνες: 1) μια *ρουτίνα δημιουργίας* mini-batches (παρτίδων) δεδομένων εκπαίδευσης και ελέγχου, αντίστοιχα, 2) μια *ρουτίνα ελέγχου* του εκάστοτε ταξινομητή στις παρτίδες δεδομένων (train/test): α) RandomClassifier(), β) LogisticRegressionClassifier(), γ) kNNClassifier καθώς και των ταξινομητών των ζητημάτων 1.4, 1.5, 1.6 και 2.2, 2.4, 2.5. Στη συνέχεια η συνάρτηση train_test_split() διαχωρίζει το σύνολο δεδομένων σε δεδομένα μάθησης (training set: <X_train, y_train>) και ελέγχου (test set: <X_test, y_test>).\n",
    "\n",
    "Ο κώδικας που ακολουθεί στη συνέχεια ορίζει κάποιες συναρτήσεις/μεθόδους για 3 ταξινομητές: 2 για τον RandomClassifier() και 3 μεθόδους για τους ταξινομητές LogisticRegressionClassifier() και kNNClassifier(). Οι 2 τελευταίες κλάσσεις έχουν μια μέθοδο __init__ για αρχικοποίηση, μια μέθοδο **train** για την εκπαίδευση του μοντέλου και μια μέθοδο __call__ για την πραγματοποίηση προβλέψεων. Πρέπει να συμπληρώσετε τα μέρη κώδικα που λείπουν από τις κλάσεις LogisticRegressionClassifier και kNNClassifier, χρησιμοποιώντας τις υλοποιήσεις `LogisticRegression` και `KNeighborsClassifier` από το Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDZ8BK3Ol4ts"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "#### Some helper functions are given below####\n",
    "def DataBatch(data, label, batchsize, shuffle=True):\n",
    "    \"\"\"\n",
    "    This function provides a generator for batches of data that \n",
    "    yields data (batchsize, 3, 32, 32) and labels (batchsize)\n",
    "    if shuffle, it will load batches in a random order\n",
    "    \"\"\"\n",
    "    n = data.shape[0]\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(n)\n",
    "    else:\n",
    "        index = np.arange(n)\n",
    "    for i in range(int(np.ceil(n/batchsize))):\n",
    "        inds = index[i*batchsize : min(n,(i+1)*batchsize)]\n",
    "        yield data[inds], label[inds]\n",
    "\n",
    "def test(testData, testLabels, classifier):\n",
    "    \"\"\"\n",
    "    Call this function to test the accuracy of a classifier\n",
    "    \"\"\"\n",
    "    batchsize=50\n",
    "    correct=0.\n",
    "    for data,label in DataBatch(testData,testLabels,batchsize,shuffle=False):\n",
    "        prediction = classifier(data)\n",
    "        correct += np.sum(prediction==label)\n",
    "    return correct/testData.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQ0N2RCZl4tt"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "# Split data into 90% train and 10% test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.images.reshape((len(digits.images), -1)), digits.target, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6JnXh3jl4tt"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class RandomClassifier():\n",
    "    \"\"\"\n",
    "    This is a sample classifier. \n",
    "    given an input it outputs a random class\n",
    "    \"\"\"\n",
    "    def __init__(self, classes=10):\n",
    "        self.classes=classes\n",
    "    def __call__(self, x):\n",
    "        return np.random.randint(self.classes, size=x.shape[0])\n",
    "    \n",
    "class LogisticRegressionClassifier():\n",
    "    def __init__(self, sol='liblinear'):\n",
    "        \"\"\"\n",
    "        Initialize Logistic Regression model.\n",
    "        \n",
    "        Inputs:\n",
    "        sol: Solver method that the Logistic Regression model would use for optimization\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        \"\"\"\n",
    "        Train your model with image data and corresponding labels.\n",
    "        \n",
    "        Inputs:\n",
    "        trainData: Training images (N,64)\n",
    "        trainLabels: Labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Predict the trained model on test data.\n",
    "\n",
    "        Inputs:\n",
    "        x: Test images (N,64)\n",
    "\n",
    "        Returns:\n",
    "        predicted labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "    \n",
    "class kNNClassifier():\n",
    "    def __init__(self, k=3, algorithm='brute'):\n",
    "        \"\"\"\n",
    "        Initialize KNN model.\n",
    "        \n",
    "        Inputs:\n",
    "        k: number of neighbors involved in voting\n",
    "        algorithm: Algorithm used to compute nearest neighbors\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        \"\"\"\n",
    "        Train your model with image data and corresponding labels.\n",
    "        \n",
    "        Inputs:\n",
    "        trainData: Training images (N,64)\n",
    "        trainLabels: Labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Predict the trained model on test data.\n",
    "\n",
    "        Inputs:\n",
    "        x: Test images (N,64)\n",
    "\n",
    "        Returns:\n",
    "        predicted labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQ9k9kw-l4tt"
   },
   "outputs": [],
   "source": [
    "# TEST CODE: DO NOT CHANGE\n",
    "randomClassifierX = RandomClassifier()\n",
    "print ('Random classifier accuracy: %f'%test(X_test, y_test, randomClassifierX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOGbN8GDl4tu"
   },
   "outputs": [],
   "source": [
    "# TEST CODE: DO NOT CHANGE\n",
    "# TEST LogisticRegressionClassifier\n",
    "\n",
    "lrClassifierX = LogisticRegressionClassifier()\n",
    "lrClassifierX.train(X_train, y_train)\n",
    "print ('Logistic Regression Classifier classifier accuracy: %f'%test(X_test, y_test, lrClassifierX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WN3IyTafl4tu"
   },
   "outputs": [],
   "source": [
    "# TEST kNNClassifier\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "\n",
    "print('k-NN Classifier accuracy: %f' % test(X_test, y_test, knnClassifierX))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt39SvrEl4tv"
   },
   "source": [
    "### Ζήτημα 1.4: Πίνακας Σύγχυσης [4 μονάδες]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jm0Zmzcl4tv"
   },
   "source": [
    "Ένας πίνακας σύγχυσης είναι ένας 2Δ πίνακας που χρησιμοποιείται συχνά για να περιγράψει την απόδοση ενός μοντέλου ταξινόμησης σε ένα σύνολο δεδομένων ελέγχου/δοκιμής (test data) για τα οποία είναι γνωστές οι πραγματικές τιμές (known labels). Εδώ θα υλοποιήσετε τη συνάρτηση που υπολογίζει τον πίνακα σύγχυσης για έναν ταξινομητή. Ο πίνακας (M) πρέπει να είναι $n \\times n$ όπου $n$ είναι ο αριθμός των κλάσεων/κατηγοριών. Η καταχώριση `M[i,j]` πρέπει να περιέχει το ποσοστό/λόγο των εικόνων της κατηγορίας `i` που ταξινομήθηκε ως κατηγορία `j`. Αν οι καταχωρήσεις `M[i,j]` έχουν υπολογιστεί σωστά, τότε τα στοιχεία `M[k,j]` κατά μήκος μιας γραμμής $k$ για $j \\neq k$ (εκτός της κύριας διαγωνίου) αναμένεται να αντιστοιχούν σε \"ψευδώς αρνητικές\" ταξινομήσεις (false negatives), ενώ τα στοιχεία `M[i,k]` κατά μήκος μιας στήλης $k$ για $i \\neq k$ (εκτός της κύριας διαγωνίου) αναμένεται να αντιστοιχούν σε \"ψευδώς θετικές\" ταξινομήσεις (false positives). Το ακόλουθο παράδειγμα δείχνει τον πίνακα σύγχυσης για τον `RandomClassifier` ταξινομητή. Ο στόχος σας είναι να σχεδιάσετε τα αποτελέσματα για τον `LogisticRegressionClassifier` και τον `kNNClassifier` ταξινομητή.\n",
    "\n",
    "<!-- <img src=\"./images/eg_confusion.PNG\" alt=\"drawing\" width=\"250\"/> -->\n",
    "![confusion](images/eg_confusion.PNG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HP43z3lOl4tv"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def Confusion(testData, testLabels, classifier):\n",
    "    batchsize=50\n",
    "    correct=0\n",
    "    M=np.zeros((10,10))\n",
    "    num=testData.shape[0]/batchsize\n",
    "    count=0\n",
    "    acc=0\n",
    "    \n",
    "    for data,label in tqdm(DataBatch(testData,testLabels,batchsize,shuffle=False),total=len(testData)//batchsize):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "\n",
    "    # Calculate accuracy\n",
    "    # acc = correct / count * 100.0\n",
    "    \n",
    "    return M, acc\n",
    "    \n",
    "def VisualizeConfussion(M):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.imshow(M)\n",
    "    plt.show()\n",
    "    print(np.round(M,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suvefA82l4tv"
   },
   "outputs": [],
   "source": [
    "# TEST/PLOT CODE: DO NOT CHANGE\n",
    "# TEST LogisticRegressionClassifier\n",
    "\n",
    "M,acc = Confusion(X_test, y_test, lrClassifierX)\n",
    "VisualizeConfussion(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWZFcKjal4tw"
   },
   "outputs": [],
   "source": [
    "# TEST/PLOT CODE: DO NOT CHANGE\n",
    "# TEST kNNClassifier\n",
    "\n",
    "M,acc = Confusion(X_test, y_test, knnClassifierX)\n",
    "VisualizeConfussion(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HnFGSRFl4tw"
   },
   "source": [
    "### Ζήτημα 1.5: κ-Κοντινότεροι Γείτονες (k-Nearest Neighbors/kNN) [7 μονάδες]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l8Vxkoil4tw"
   },
   "source": [
    "Για αυτό το πρόβλημα, θα ολοκληρώσετε έναν απλό ταξινομητή kNN χωρίς χρήση του πακέτου Sklearn. Η μέτρηση της απόστασης είναι η Ευκλείδεια απόσταση (L2 norm) στον χώρο των pixel. Μπορείτε να χρησιμοποιήσετε τη συνάρτηση **np.linalg.norm** για να υπολογίσετε την απόσταση. Το $k$ αναφέρεται στον αριθμό των γειτόνων που συμμετέχουν στην ψηφοφορία για την ομάδα/κλάση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-D-znLZl4tx"
   },
   "outputs": [],
   "source": [
    "class kNNClassifier_v1_5():\n",
    "    def __init__(self, k=3):\n",
    "        self.k=k\n",
    "\n",
    "    def train(self, trainData, trainLabels):\n",
    "        self.X_train = trainData\n",
    "        self.y_train = trainLabels\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for the input data using KNN method.\n",
    "\n",
    "        Inputs:\n",
    "        X: Test images (N,64)\n",
    "\n",
    "        Returns:\n",
    "        predicted labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPVvwhp0l4tx"
   },
   "outputs": [],
   "source": [
    "# TEST/PLOT CODE: DO NOT CHANGE\n",
    "# TEST kNNClassifierManual\n",
    "\n",
    "knnClassifierManualX = kNNClassifier_v1_5()\n",
    "knnClassifierManualX.train(X_train, y_train)\n",
    "print ('kNN classifier accuracy: %f'%test(X_test, y_test, knnClassifierManualX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZQQIiKPnRQF"
   },
   "source": [
    "### Ζήτημα 1.6: PCA + κ-κοντινότεροι γείτονες (PCA/k-NN) [8 μονάδες] \n",
    "\n",
    "Σε αυτό το ζήτημα θα εφαρμόσετε έναν απλό ταξινομητή kNN, αλλά στον χώρο PCA, δηλαδή όχι τον χώρο των πίξελ, αλλά αυτόν\n",
    "που προκύπτει μετά από ανάλυση σε πρωτεύουσες συνιστώσες των εικόνων του συνόλου εκπαίδευσης (για k=3 και 25 πρωτεύουσες συνιστώσες).\n",
    "\n",
    "Θα πρέπει να υλοποιήσετε μόνοι σας την PCA χρησιμοποιώντας \"Singular Value Decomposition (SVD)\".\n",
    "Η χρήση του `sklearn.decomposition.PCA` ή οποιουδήποτε άλλου πακέτου που υλοποιεί άμεσα μετασχηματισμούς PCA θα οδηγήσει σε μείωση μονάδων.\n",
    "\n",
    "Μπορείτε να χρησιμοποιήσετε την προηγούμενη υλοποίηση του ταξινομητή kNN σε αυτό το ζήτημα.\n",
    "\n",
    "Είναι ο χρόνος ελέγχου για τον ταξινομητή PCA-kNN μεγαλύτερος ή μικρότερος από αυτόν για τον ταξινομητή kNN; Εφόσον διαφέρει, σχολιάστε γιατί στο τέλος της άσκησης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e06z90dxm7Af",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def svd(A):\n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "    return U, singular_values, V.T\n",
    "\n",
    "        \n",
    "\n",
    "class PCAKNNClassifer():\n",
    "    def __init__(self, components=25, k=3):\n",
    "        \"\"\"\n",
    "        Initialize PCA kNN classifier\n",
    "\n",
    "        Inputs:\n",
    "        components: number of principal components\n",
    "        k: number of neighbors involved in voting\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        \"\"\"\n",
    "        Train your model with image data and corresponding labels.\n",
    "        \n",
    "        Inputs:\n",
    "        trainData: Training images (N,64)\n",
    "        trainLabels: Labels (N,)\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "\n",
    "        # Perform SVD on centered data (mean-deviation form of data matrix)\n",
    "        U, D, V = svd(X_hat)\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Predict the trained model on test data.\n",
    "\n",
    "        Inputs:\n",
    "        x: Test images (N,64)\n",
    "\n",
    "        Returns:\n",
    "        predicted labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "    \n",
    "\n",
    "# test your classifier with only the first 100 training examples (use this\n",
    "# while debugging)\n",
    "pcaknnClassiferX = PCAKNNClassifer()\n",
    "pcaknnClassiferX.train(X_train[:100], y_train[:100])\n",
    "print ('PCA-kNN classifier accuracy: %f'%test(X_test, y_test, pcaknnClassiferX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSbD_cdeoOY5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test your classifier with all the training examples\n",
    "pcaknnClassifer = PCAKNNClassifer()\n",
    "pcaknnClassifer.train(X_train, y_train)\n",
    "# display confusion matrix for your PCA KNN classifier with all the training examples\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "\n",
    "# Display the accuracy and visualize the confusion matrix\n",
    "print ('PCA-kNN classifier accuracy: %f'%test(X_test, y_test, pcaknnClassifer))\n",
    "VisualizeConfussion(M_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuQfPRnEpM9c"
   },
   "source": [
    "- Σχολιασμός του χρόνου εκτέλεσης PCA-kNN σε σχέση με τον kNN.\n",
    "\n",
    "\"\"\" \n",
    "WRITE YOUR ANWSER HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8ol8VCDpV8Q"
   },
   "source": [
    "## Άσκηση 2: Βαθιά Μάθηση [25 μονάδες]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYf3GsdmpfvS"
   },
   "source": [
    "### Ζήτημα 2.1 Αρχική Εγκατάσταση (απεικόνιση παραδειγμάτων) [1 μονάδα]\n",
    "\n",
    "- **Τοπικά** (jupyter):\n",
    "Ακολουθήστε τις οδηγίες στη διεύθυνση https://pytorch.org/get-started/locally/ για να εγκαταστήσετε την PyΤorch τοπικά στον υπολογιστή σας.\n",
    "Για παράδειγμα, αφού δημιουργήσετε και ενεργοποιήσετε κάποιο εικονικό περιβάλλον anaconda με τις εντολές: π.χ. `(base)$ conda create -n askisi3`, `(base)$ conda activate askisi3`, η εντολή `(askisi3)$ conda install pytorch torchvision torchaudio cpuonly -c pytorch` εγκαθιστά την βιβλιοθήκη \"PyTorch\" σε περιβάλλον Linux/Windows χωρίς GPU υποστήριξη.\n",
    "\n",
    "**Προσοχή** σε αυτό το σημείο, αν τρέχετε την άσκηση τοπικά σε jupyter, εκτός της εγκατάστασης του PyTorch, θα χρειαστούν ξανά και κάποιες βιβλιοθήκες `matplotlib`, `scipy`, `tqdm` και `sklearn` (όπως και στην 1η άσκηση), μέσα στο περιβάλλον 'askisi3', πριν ανοίξετε το jupyter: `(askisi3)$ conda install matplotlib tqdm scipy` και `(askisi3)$ conda install -c anaconda scikit-learn`. Αυτό χρειάζεται διότι σε ορισμένες περιπτώσεις, αφού εγκαταστήσετε τις βιβλιοθήκες που απαιτούνται, πρέπει να εξασφαλίσετε ότι ο *Python Kernel* αναγνωρίζει την προϋπάρχουσα εγκατάσταση (PyTorch, matplotlib, tqdm, κτλ.).\n",
    "Τέλος, χρειάζεται να εγκαταστήσετε το jupyter ή jupyterlab μέσω του περιβάλλοντος conda: `(askisi3)$ conda install jupyter` και μετά να εκτελέσετε `(askisi3)$ jupyter notebook` για να ανοίξετε το jupyter με τη σωστή εγκατάσταση. Αν όλα έχουν γίνει σωστά, θα πρέπει ο *Python Kernel* να βλέπει όλα τα 'modules' που χρειάζεστε στη 2η άσκηση. Διαφορετικά, μπορείτε να εγκαταστήσετε εξ' αρχής όλες τις βιβλιοθήκες, από την αρχή υλοποίησης της 3ης σειράς ασκήσεων, μέσα στο εικονικό περιβάλλον *askisi3* ώστε να μην είναι απαραίτητη εκ νέου η εγκατάσταση των βιβλιοθηκών που θα χρειαστούν στη 2η άσκηση.\n",
    "\n",
    "- **Colab**: **Αν** χρησιμοποιείτε google colab, τότε δεν θα χρειαστεί λογικά κάποιο βήμα εγκατάστασης. Αν ωστόσο σας παρουσιαστεί κάποιο πρόβλημα με απουσία πακέτου, π.χ. \"ModuleNotFoundError - torchvision\", τότε μπορείτε απλώς να το εγκαταστήσετε με χρήση του εργαλείου `pip` εκτελώντας την αντίστοιχη εντολή (π.χ. \"!pip install torchvision\") σε ένα νέο κελί του notebook.\n",
    "\n",
    "Σημείωση: Δεν θα είναι απαραίτητη η χρήση GPU για αυτήν την άσκηση, γι' αυτό μην ανησυχείτε αν δεν έχετε ρυθμίσει την εγκατάσταση με υποστήριξη GPU. Επιπλέον, η εγκατάσταση με υποστήριξη GPU είναι συχνά πιο δύσκολη στη διαμόρφωση, γι' αυτό και προτείνεται να εγκαταστήσετε μόνο την έκδοση CPU. Ο Διδάσκων δεν θα παρέχει καμία υποστήριξη που σχετίζεται με GPU ή την CUDA.\n",
    "\n",
    "Εκτελέστε τις παρακάτω εντολές για να επαληθεύσετε την εγκατάστασή σας (PyTorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQC44M9Rp1VR"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# create a tensor of 4x3 random-valued array\n",
    "x = torch.rand(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ai7Lktn5tLBz"
   },
   "source": [
    "Σε αυτή την άσκηση, θα χρησιμοποιήσουμε το πλήρες σύνολο δεδομένων της βάσης δεδομένων MNIST με τις εικόνες ψηφίων 28x28 pixel (60.000 εικόνες εκπαίδευσης, 10.000 εικόνες ελέγχου).\n",
    "\n",
    "Ο κώδικας που ακολουθεί \"κατεβάζει\" το σύνολο δεδομένων MNIST της κλάσης [torchvision.datasets](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST), στο φάκελο `mnist` (του root καταλόγου). \n",
    "Μπορείτε να αλλάξετε τον κατάλογο που δείχνει η μεταβλητή `path` στη διαδρομή που επιθυμείτε. Ενδεικτικό `path` σε περιβάλλον Windows: **path = 'C:/Users/user/Υπολογιστική Όραση/assignments/assignment 3/'**. Στην περίπτωση που εργάζεστε μέσω **colab** μπορεί να χρειαστεί η φόρτωση του καταλόγου στο drive, εκτελώντας `from google.colab import drive` και `drive.mount('/content/gdrive')` και μετά θέτοντας π.χ το **path = '/content/gdrive/assignment3/'**.\n",
    "\n",
    "- Θα πρέπει να απεικονίσετε σε ένα σχήμα 2x5 ένα τυχαίο παράδειγμα εικόνας που αντιστοιχεί σε κάθε ετικέτα (κατηγορία) από τα δεδομένα εκπαίδευσης (αντίστοιχα του ζητήματος 1.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# import additional libs in case not already done in 'askisi 1'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the dataset directory\n",
    "path = './mnist/'\n",
    "\n",
    "# Load the MNIST training dataset\n",
    "train_dataset = datasets.MNIST(root=path, train=True, download=True)\n",
    "\n",
    "# Extract the images and labels from the training dataset\n",
    "X_train = train_dataset.data.numpy()\n",
    "y_train = train_dataset.targets.numpy()\n",
    "\n",
    "# Load the MNIST testing dataset\n",
    "test_dataset = datasets.MNIST(root=path, train=False, download=True)\n",
    "\n",
    "# Extract the images and labels from the testing dataset\n",
    "X_test = test_dataset.data.numpy()\n",
    "y_test = test_dataset.targets.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5tK3MeXN5v2"
   },
   "outputs": [],
   "source": [
    "def plot_mnist_sample_high_res(X_train, y_train):\n",
    "    \"\"\"\n",
    "    This function plots a sample image for each category,\n",
    "    The result is a figure with 2x5 grid of images.\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNCBDoFnN8B5"
   },
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT CHANGE\n",
    "# This code is for you to plot the results.\n",
    "\n",
    "plot_mnist_sample_high_res(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wu-weDbqEAY"
   },
   "source": [
    "### Ζήτημα 2.2:  Εκπαίδευση Νευρωνικού Δικτύου με PyTorch [6 μονάδες]\n",
    "Ακολουθεί ένα τμήμα βοηθητικού κώδικα για την εκπαίδευση των βαθιών νευρωνικών δικτύων (Deep Neural Networks - DNN).\n",
    "\n",
    "- Ολοκληρώστε τη συνάρτηση train_net() για το παρακάτω DNN.\n",
    "\n",
    "Θα πρέπει να συμπεριλάβετε τις λειτουργίες της διαδικασίας της εκπαίδευσης σε αυτή τη συνάρτηση. Αυτό σημαίνει ότι για μια παρτίδα/υποσύνολο δεδομένων (batch μεγέθους 50) πρέπει να αρχικοποιήσετε τις παραγώγους, να υλοποιήσετε τη διάδοση προς τα εμπρός της πληροφορίας (forward propagation), να υπολογίσετε το σφάλμα εκτίμησης, να κάνετε οπισθοδιάδοση της πληροφορίας (μετάδοση προς τα πίσω των παραγώγων σφάλματος ως προς τα βάρη - backward propagation), και τέλος, να ενημερώσετε τις παραμέτρους (weight update). Θα πρέπει να επιλέξετε μια κατάλληλη συνάρτηση απώλειας και βελτιστοποιητή (optimizer) από την βιβλιοθήκη PyTorch για αυτό το πρόβλημα.\n",
    "\n",
    "Αυτή η συνάρτηση θα χρησιμοποιηθεί στα επόμενα ζητήματα με διαφορετικά δίκτυα. Θα μπορείτε δηλαδή να χρησιμοποιήσετε τη μέθοδο `train_net` για να εκπαιδεύσετε το βαθύ νευρωνικό σας δίκτυο, εφόσον προσδιορίσετε τη συγκεκριμένη αρχιτεκτονική σας και εφαρμόσετε το `forward pass` σε μια υπο/κλάσση της DNN (βλ. παράδειγμα \"LinearClassifier(DNN)\").\n",
    "Μπορείτε να ανατρέξετε στη διεύθυνση https://pytorch.org/tutorials/beginner/pytorch_with_examples.html για περισσότερες πληροφορίες.\n",
    "Επίσης, ένα αρκετά χρήσιμο \"tutorial\" περιλαμβάνεται στο σημειωματάριο jupyter `(tutorial1_pytorch_introduction.ipynb)` στη σελίδα ecourse του μαθήματος.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky0FksEwqDta"
   },
   "outputs": [],
   "source": [
    "# base class for your deep neural networks. It implements the training loop (train_net).\n",
    "\n",
    "\n",
    "import torch.nn.init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def train_net(self, X_train, y_train, epochs=1, batchSize=50):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "    \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        inputs = Variable(torch.FloatTensor(x))\n",
    "        prediction = self.forward(inputs)\n",
    "        return np.argmax(prediction.data.cpu().numpy(), 1)\n",
    "\n",
    "# helper function to get weight variable\n",
    "def weight_variable(shape):\n",
    "    initial = torch.Tensor(truncnorm.rvs(-1/0.01, 1/0.01, scale=0.01, size=shape))\n",
    "    return Parameter(initial, requires_grad=True)\n",
    "\n",
    "# helper function to get bias variable\n",
    "def bias_variable(shape):\n",
    "    initial = torch.Tensor(np.ones(shape)*0.1)\n",
    "    return Parameter(initial, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HYVuzbtosJo"
   },
   "outputs": [],
   "source": [
    "# example linear classifier - input connected to output\n",
    "# you can take this as an example to learn how to extend DNN class\n",
    "class LinearClassifier(DNN):\n",
    "    def __init__(self, in_features=28*28, classes=10):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        # in_features=28*28\n",
    "        self.weight1 = weight_variable((classes, in_features))\n",
    "        self.bias1 = bias_variable((classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # linear operation\n",
    "        y_pred = torch.addmm(self.bias1, x.view(list(x.size())[0], -1), self.weight1.t())\n",
    "        return y_pred\n",
    "\n",
    "X_train=np.float32(np.expand_dims(X_train,-1))/255\n",
    "X_train=X_train.transpose((0,3,1,2))\n",
    "\n",
    "X_test=np.float32(np.expand_dims(X_test,-1))/255\n",
    "X_test=X_test.transpose((0,3,1,2))\n",
    "\n",
    "## In case abovementioned 4 lines return error: Modify the lines for transposing X_train\n",
    "## and X_test by uncommenting the following 4 lines and place the 4 lines above in comments\n",
    "\n",
    "#X_train = np.float32(X_train) / 255.0\n",
    "#X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "\n",
    "#X_test = np.float32(X_test) / 255.0\n",
    "#X_test = X_test.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-UGSj6FqRKf"
   },
   "outputs": [],
   "source": [
    "# test the example linear classifier (note you should get around 90% accuracy\n",
    "# for 10 epochs and batchsize 50)\n",
    "linearClassifier = LinearClassifier()\n",
    "linearClassifier.train_net(X_train, y_train, epochs=10)\n",
    "\n",
    "print ('Linear classifier accuracy: %f'%test(X_test, y_test, linearClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RA5688oyNTu"
   },
   "outputs": [],
   "source": [
    "# display confusion matrix\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNzcCiLr0AU8"
   },
   "source": [
    "### Ζήτημα 2.3: Οπτικοποίηση Βαρών (Visualizing Weights of Single Layer Perceptron) [3 μονάδες]\n",
    "Αυτός ο απλός γραμμικός ταξινομητής που υλοποιείται στο παραπάνω κελί (το μοντέλο απλά επιστρέφει ένα γραμμικό συνδυασμό της εισόδου) παρουσιάζει ήδη αρκετά καλά αποτελέσματα.\n",
    "\n",
    "- Σχεδιάστε τα βάρη του φίλτρου που αντιστοιχούν σε κάθε κατηγορία εξόδου (τα **βάρη**/weights, όχι τους όρους *bias*) ως εικόνες. Κανονικοποιήστε τα βάρη ώστε να βρίσκονται μεταξύ 0 και 1 ( $z_i = (w_i - min(w)) / (max(w) – min(w))$ ). Χρησιμοποιήστε έγχρωμους χάρτες όπως \"inferno\" ή \"plasma\" για καλά αποτελέσματα (π.χ. cmap='inferno', ως όρισμα της imshow()).\n",
    "\n",
    "- Σχολιάστε με τι μοιάζουν τα βάρη και γιατί μπορεί να συμβαίνει αυτό.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8S3dYZgzzT_"
   },
   "outputs": [],
   "source": [
    "# Plot filter weights corresponding to each class, you may have to reshape them to make sense out of them\n",
    "# linearClassifier.weight1.data will give you the first layer weights\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmQUOBNg0PkW"
   },
   "source": [
    "#### Σχολιασμός των βαρών\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJBWgsBE0S7K"
   },
   "source": [
    "### Ζήτημα 2.4: Νευρωνικό δίκτυο πολλαπλών επιπέδων - Multi Layer Perceptron (MLP) [7 μονάδες]\n",
    "Θα υλοποιήσετε ένα MLP νευρωνικό δίκτυο. Το MLP θα πρέπει να αποτελείται από 2 επίπεδα (πολλαπλασιασμός βάρους και μετατόπιση μεροληψίας/bias - γραμμικός συνδυασμός εισόδου) που απεικονίζονται (map) στις ακόλουθες διαστάσεις χαρακτηριστικών:\n",
    "\n",
    "* 28x28 -> hidden (50)\n",
    "* hidden (50) -> classes\n",
    "\n",
    "* Το κρυμμένο επίπεδο πρέπει να ακολουθείται από μια μη γραμμική συνάρτηση ενεργοποίησης ReLU. Το τελευταίο επίπεδο δεν θα πρέπει να έχει εφαρμογή μη γραμμικής απεικόνισης καθώς επιθυμούμε την έξοδο ακατέργαστων 'logits' (στη μηχανική μάθηση, τα logits είναι οι τιμές που παράγονται από το τελικό επίπεδο ενός μοντέλου πριν περάσουν από μια συνάρτηση ενεργοποίησης softmax. Αντιπροσωπεύουν τις προβλέψεις του μοντέλου για κάθε κατηγορία χωρίς να μετατρέπονται σε πιθανότητες).\n",
    "* Η τελική έξοδος του υπολογιστικού γράφου (μοντέλου) θα πρέπει να αποθηκευτεί στο self.y καθώς θα χρησιμοποιηθεί στην εκπαίδευση.\n",
    "\n",
    "Εμφανίστε τον πίνακα σύγχυσης (confusion matrix - υλοποίηση 1ης άσκησης) και την ακρίβεια (accuracy) μετά την εκπαίδευση. Σημείωση: Θα πρέπει να έχετε ~95% ακρίβεια για 10 εποχές (epochs) και μέγεθος παρτίδας (batch size) 50.\n",
    "\n",
    "Σχεδιάστε τα βάρη του φίλτρου που αντιστοιχούν στην αντιστοίχιση από τις εισόδους στις πρώτες 10 εξόδους του κρυμμένου επιπέδου (από τις 50 συνολικά). Μοιάζουν τα βάρη αυτά καθόλου με τα βάρη που απεικονίστηκαν στο προηγούμενο ζήτημα; Γιατί ή γιατί όχι?\n",
    "\n",
    "Αναμένεται ότι το μοντέλο εκπαίδευσης θα διαρκέσει από 1 έως μερικά λεπτά για να τρέξει, ανάλογα με τις δυνατότητες της CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ss2lUgpL0JRh"
   },
   "outputs": [],
   "source": [
    "class MLPClassifer(DNN):\n",
    "    def __init__(self, in_features=28*28, classes=10, hidden=50):\n",
    "        \"\"\"\n",
    "        Initialize weight and bias variables\n",
    "        \"\"\"\n",
    "        super(MLPClassifer, self).__init__()\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "    \n",
    "\n",
    "mlpClassifer = MLPClassifer()\n",
    "mlpClassifer.train_net(X_train, y_train, epochs=10, batchSize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-4xraHl0muj"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "M_mlp,acc_mlp = Confusion(X_test, y_test, mlpClassifer)\n",
    "\n",
    "print ('Confusion matrix - MLP classifier accuracy: %f'%acc_mlp)\n",
    "\n",
    "# Check also standard accucary of test() for consistency\n",
    "print ('MLP classifier accuracy: %f'%test(X_test, y_test, mlpClassifer))\n",
    "\n",
    "VisualizeConfussion(M_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLD0yjHH0bVU"
   },
   "outputs": [],
   "source": [
    "# Plot filter weights\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBC6s9qQ1KKj"
   },
   "source": [
    "### Ζήτημα 2.5: Συνελικτικό Νευρωνικό Δίκτυο - Convolutional Neural Network (CNN) [8 μονάδες]\n",
    "Εδώ θα υλοποιήσετε ένα CNN με την ακόλουθη αρχιτεκτονική:\n",
    "\n",
    "* n=10 (output features or filters)\n",
    "* ReLU( Conv(kernel_size=5x5, stride=2, output_features=n) )\n",
    "* ReLU( Conv(kernel_size=5x5, stride=2, output_features=n*2) )\n",
    "* ReLU( Linear(hidden units = 64) )\n",
    "* Linear(output_features=classes)\n",
    "\n",
    "Δηλαδή, 2 συνελικτικά επίπεδα (Conv Layers) όπου απεικονίζουν μη-γραμμικά (ReLU) την είσοδο του προηγούμενου επιπέδου, ακολουθούμενα από 1 πλήρως συνδεδεμένο κρυμμένο επίπεδο (FC hidden layer) με μη γραμμική ενεργοποίηση (ReLU) και μετά το επίπεδο εξόδου (output layer) όπου συνδυάζει γραμμικά τις τιμές του προηγούμενου επιπέδου.\n",
    "\n",
    "Εμφανίστε τον πίνακα σύγχυσης και την ακρίβεια μετά την εκπαίδευση. Θα πρέπει να έχετε περίπου ~98% ακρίβεια για 10 εποχές και μέγεθος παρτίδας 50.<br><br>\n",
    "\n",
    "**Σημείωση: Δεν επιτρέπεται να χρησιμοποιείτε τις torch.nn.Conv2d() και torch.nn.Linear(). Η χρήση αυτών θα οδηγήσει σε αφαίρεση μονάδων. Χρησιμοποιήστε τις δηλωμένες συναρτήσεις conv2d(), weight_variable() και bias_variable().** Ωστόσο στην πράξη, όταν προχωρήσετε μετά από αυτό το μάθημα, θα χρησιμοποιήσετε torch.nn.Conv2d() που κάνει τη ζωή πιο εύκολη και αποκρύπτει όλες τις υποφαινόμενες λειτουργίες.\n",
    "\n",
    "**Μην** ξεχάσετε να σχολιάσετε τον κώδικά σας όπου χρειάζεται (π.χ. στον τρόπο υπολογισμού των διαστάσεων της εξόδου σε κάθε επίπεδο)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OhmF0NM1Clj"
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, stride, bias=None):\n",
    "    # x: input\n",
    "    # W: weights (out, in, kH, kW)\n",
    "    return F.conv2d(x, W, bias, stride=stride, padding=2)\n",
    "\n",
    "# Defining a Convolutional Neural Network\n",
    "class CNNClassifer(DNN):\n",
    "    def __init__(self, classes=10, n=10):\n",
    "        super(CNNClassifer, self).__init__()\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "    def forward(self, x):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "        return y \n",
    "    \n",
    "cnnClassifer = CNNClassifer()\n",
    "cnnClassifer.train_net(X_train, y_train, epochs=10, batchSize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWkNhBgf1Sf3"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix and print the test accuracy of the classifier\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    " ========== \"\"\"\n",
    "\n",
    "print ('Confusion matrix - MLP classifier accuracy: %f'%acc_cnn)\n",
    "\n",
    "# Check also standard accucary of test() for consistency\n",
    "print ('MLP classifier accuracy: %f'%test(X_test, y_test, cnnClassifer))\n",
    "\n",
    "VisualizeConfussion(M_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHx9gSiK1xVp"
   },
   "source": [
    "* Σημειώστε ότι οι προσεγγίσεις MLP/ConvNet οδηγούν σε λίγο μεγαλύτερη ακρίβεια ταξινόμησης από την προσέγγιση K-NN. \n",
    "* Στη γενική περίπτωση, οι προσεγγίσεις Νευρωνικών Δικτύων οδηγούν σε σημαντική αύξηση της ακρίβειας, αλλά, σε αυτή την περίπτωση, εφόσον το πρόβλημα δεν είναι ιδιαίτερα δύσκολο, η αύξηση της ακρίβειας δεν είναι και τόσο υψηλή.\n",
    "* Ωστόσο, αυτό εξακολουθεί να είναι αρκετά σημαντικό, δεδομένου του γεγονότος ότι τα ConvNets που χρησιμοποιήσαμε είναι σχετικά απλά, ενώ η ακρίβεια που επιτυγχάνεται χρησιμοποιώντας το K-NN είναι αποτέλεσμα αναζήτησης σε πάνω από 60.000 εικόνες εκπαίδευσης για κάθε εικόνα ελέγχου.\n",
    "* Συνιστάται ιδιαίτερα να αναζητήσετε περισσότερα για τα νευρωνικά δίκτυα/PyTorch στη διεύθυνση<br> https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html καθώς και στο σχετικό tutorial στη σελίδα ecourse του μαθήματος **tutorial1_pytorch_introduction.ipynb**.\n",
    "* Τέλος, μπορείτε ακόμη να πειραματιστείτε (από δικό σας ενδιαφέρον) με ένα demo νευρωνικού δικτύου που δημιουργήθηκε από τους Daniel Smilkov και Shan Carter στη διεύθυνση https://playground.tensorflow.org/ (για πλατφόρμα TensorFlow).\n",
    "\n",
    "\n",
    "\n",
    "## Οδηγίες υποβολής\n",
    "\n",
    "Μην ξεχάσετε να κάνετε turnin το αρχείο Jupyter notebook **και** το PDF αρχείο αυτού του notebook μαζί με το συνοδευτικό αρχείο `onoma.txt`:\n",
    "**turnin  assignment_3@mye046 onoma.txt assignment3.ipynb assignment3.pdf**\n",
    "\n",
    "Βεβαιωθείτε ότι το περιεχόμενο σε **κάθε κελί εμφανίζεται** καθαρά στο τελικό σας αρχείο PDF.\n",
    "Για να μετατρέψετε το σημειωματάριο σε PDF, μπορείτε να επιλέξετε **έναν** από τους παρακάτω τρόπους:\n",
    "\n",
    "1. Google Colab (Συνιστάται): You can `print` the web page and save as PDF (e.g. Chrome: Right click the web page $\\rightarrow$ Print... $\\rightarrow$ Choose \"Destination: Save as PDF\" and click \"Save\"). Προσοχή στην περίπτωση όπου κώδικας/σχόλια εμφανίζονται εκτός των ορίων της σελίδας. Μια λύση είναι η αλλαγή γραμμής π.χ. σε σχόλια που υπερβαίνουν το πλάτος της σελίδας.\n",
    "* Στην περίπτωση που οι εικόνες εξόδου δεν εμφανίζονται σωστά, μια λύση μέσω colab είναι (εργαλείο nbconvert):\n",
    "   * Ανέβασμα του αρχείου `assignment3.ipynb` στο home directory του Colaboratory (ο κατάλογος home είναι: /content/).\n",
    "   * Εκτελέστε σε ένα κελί colab ενός νέου notebook: `!jupyter nbconvert --to html /content/assignment3.ipynb`\n",
    "   * Κάνετε λήψη του assignment3.html τοπικά στον υπολογιστή σας και ανοίξτε το αρχείο μέσω browser ώστε να το εξάγετε ως PDF.\n",
    "\n",
    "2. Local Jupyter/JupyterLab(Συνιστάται): You can `print` the web page and save as PDF (File $\\rightarrow$ Print... $\\rightarrow$ Choose \"Destination: Save as PDF\" and click \"Save\"). Προσοχή στην περίπτωση όπου κώδικας/σχόλια εμφανίζονται εκτός των ορίων της σελίδας. Μια λύση είναι η αλλαγή γραμμής π.χ. σε σχόλια που υπερβαίνουν το πλάτος της σελίδας.\n",
    "\n",
    "3. Local Jupyter/JupyterLab(Συνιστάται!): You can `export` and save as HTML (File $\\rightarrow$ Save & Export Notebook as... $\\rightarrow$ HTML). Στη συνέχεια μπορείτε να μετατρέψεται το HTML αρχείο αποθηκεύοντάς το ως PDF μέσω ενός browser."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "jZQQIiKPnRQF",
    "aYf3GsdmpfvS",
    "6Wu-weDbqEAY",
    "mNzcCiLr0AU8",
    "zmQUOBNg0PkW",
    "7pCLEVJ_1F66"
   ],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
